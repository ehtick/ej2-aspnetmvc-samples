@using Syncfusion.EJ2
@using Syncfusion.EJ2.InteractiveChat
@using Syncfusion.EJ2.Notifications

@section ControlsSection{
    <div class="control-section integration-control-section">
        <div class="control-wrapper">
            <div class="integration-speechToText-section">
                <!-- Initialize Toast notification for errors -->
                @Html.EJS().Toast("stt-toast").Position(p => p.X("Right")).Target(".integration-control-section").CssClass("e-toast-danger").Created("onToastCreate").Render()
                <!-- Initialize AI AssistView component -->
                @Html.EJS().AIAssistView("aiAssistView").Created("onCreate").ToolbarSettings(new AIAssistViewToolbarSettings() { Items = ViewBag.ToolbarItems, ItemClicked = "toolbarItemClicked" }).PromptRequest("onPromptRequest").BannerTemplate("#bannerContent").FooterTemplate("#footerContent").Render()
            </div>
        </div>
    </div>
}

<script>
    var aiAssistViewObj;
    var toastObj;
    var assistviewFooter;
    var sendButton;
    var speechToTextObj;

    function onCreate() {
        aiAssistViewObj = ej.base.getComponent(document.getElementById("aiAssistView"), "aiassistview");
        // Initialize Speech-to-Text component
        speechToTextObj = new ej.inputs.SpeechToText({
            transcriptChanged: onTranscriptChange,
            onStop: onListeningStop,
            created: onCreated,
            onError: onErrorHandler,
            cssClass: 'e-flat'
        });
        speechToTextObj.appendTo('#speechToText');
    }

    function onToastCreate() {
        toastObj = ej.base.getComponent(document.getElementById("stt-toast"), "toast");
    }

    // Handles AI prompt requests
    function onPromptRequest(args) {
        setTimeout(function () {
            aiAssistViewObj.addPromptResponse('For real-time prompt processing, connect the AIAssistView component to your preferred AI service.');
            toggleButtons();
        }, 2000);
    }

    // Handles toolbar button clicks
    function toolbarItemClicked(args) {
        if (args.item.iconCss === 'e-icons e-refresh') {
            aiAssistViewObj.prompts = [];
        }
    }

    // Updates transcript in the input area when speech-to-text transcribes
    function onTranscriptChange(args) {
        document.querySelector('#assistview-footer').innerText = args.transcript;
    }

    // Handles actions when speech listening stops
    function onListeningStop() {
        toggleButtons();
    }

    // Handles actions after component creation
    function onCreated() {
        assistviewFooter = document.querySelector('#assistview-footer');
        sendButton = document.querySelector('#assistview-sendButton');
        sendButton.addEventListener('click', sendIconClicked);
        assistviewFooter.addEventListener('input', toggleButtons);
        assistviewFooter.addEventListener('keydown', function (e) {
            if (e.key === 'Enter' && !e.shiftKey) {
                sendIconClicked();
                e.preventDefault();
            }
        });
        toggleButtons();
    }

    // Toggles the visibility of the send and speech-to-text buttons
    function toggleButtons() {
        var hasText = assistviewFooter.innerText.trim() !== '';
        sendButton.classList.toggle('visible', hasText);
        speechToTextObj.element.classList.toggle('visible', !hasText);
        if (!hasText && (assistviewFooter.innerHTML === '<br>' || !assistviewFooter.innerHTML.trim())) {
            assistviewFooter.innerHTML = '';
        }
    }

    // Handles send button click event
    function sendIconClicked() {
        aiAssistViewObj.executePrompt(assistviewFooter.innerText);
        assistviewFooter.innerText = "";
    }

    // Handles errors and displays toast notifications
    function onErrorHandler(args) {
        toastObj.content = args.errorMessage;
        if (args.error === 'unsupported-browser') {
            this.disabled = true;
            toastObj.show({ timeOut: 0 });
        } else {
            toastObj.show({ timeOut: 5000 });
        }
    }

</script>

<script id="bannerContent" type="text/x-jsrender">
    <div class="banner-info">
        <div class="e-icons e-listen-icon"></div>
        <h3>Speech To Text</h3>
        <i>Click the below mic-button to convert your voice to text.</i>
    </div>
</script>

<script id="footerContent" type="text/x-jsrender">
    <div class="e-footer-wrapper">
        <div id="assistview-footer" class="content-editor" oninput="toggleButtons" contenteditable="true" placeholder="Click to speak or start typing..."></div>
        <div class="option-container">
            <button id="speechToText"></button>
            <button id="assistview-sendButton" class="e-assist-send e-icons" role="button"></button>
        </div>
    </div>
</script>
<style>

    .integration-speechToText-section {
        height: 550px;
        width: 550px;
        margin: 0 auto;
    }

    .integration-speechToText-section .banner-info .e-listen-icon:before {
        font-size: 35px;
    }

    .integration-speechToText-section .banner-info {
        display: flex;
        flex-direction: column;
        justify-content: center;
        height: 330px;
        text-align: center;
    }

    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton {
        width: 40px;
        height: 40px;
        font-size: 20px;
        border: none;
        background: none;
        cursor: pointer;
    }

    .integration-speechToText-section .e-footer-wrapper #speechToText.visible,
    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton.visible {
        display: inline-block;
    }

    .integration-speechToText-section .e-footer-wrapper #speechToText,
    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton {
        display: none;
    }

    @@media only screen and (max-width: 750px) {
        .integration-speechToText-section {
            width: 100%;
        }
    }

    .integration-speechToText-section .e-footer-wrapper {
        display: flex;
        border: 1px solid #c1c1c1;
        padding: 5px 5px 5px 10px;
        margin: 5px 5px 0 5px;
        border-radius: 30px;
    }

    .integration-speechToText-section .e-footer-wrapper .content-editor {
        width: 100%;
        overflow-y: auto;
        font-size: 14px;
        min-height: 25px;
        max-height: 200px;
        padding: 10px;
        scrollbar-color: #c1c1c1 transparent;
    }

    .integration-speechToText-section .e-footer-wrapper .content-editor[contentEditable=true]:empty:before {
        content: attr(placeholder)
    }

    .integration-speechToText-section .option-container {
        align-self: flex-end;
    }
</style>

@section Meta{
    <meta name="description" content="This example demonstrates the Default Functionalities in ASP.NET MVC SpeechToText control. Explore here for more details." />
}
@section ActionDescription{
    <div id="action-description">
        <p>
            This sample demonstrates the integration of SpeechToText with the AI AssistView control. It allows users to convert spoken words into text in real time and use the transcribed content as input for AI-based interactions.
        </p>
    </div>
}
@section Description{
    <div id="description">
        <p>
            In this example, the SpeechToText control captures and transcribes spoken input into text, which is displayed in an editable area. Users can modify the transcribed text or send it directly to the AI AssistView for processing.
        </p>
        <p>
            The AI AssistView responds based on the provided input. A toolbar option is available to clear the conversation history, and a toast notification alerts users to any speech recognition errors.
        </p>
    </div>
}
@section Title{
    <title>ASP.NET MVC SpeechToText Integration with the AI AssistView control Example - Syncfusion Demos </title>
}
@section Header{
    <h1 class='sb-sample-text'>Example of Integration with the AI AssistView control in ASP.NET MVC SpeechToText Control</h1>
}