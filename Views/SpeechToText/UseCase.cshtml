@using Syncfusion.EJ2
@using Syncfusion.EJ2.InteractiveChat

@section ControlsSection{
    <div class="control-section">
        <div class="usecase-speechToText-section e-message">
            <div class="stt-container">
                <!-- Microphone button for Speech-to-Text -->
                <button id="speechToText"></button>
                <span class="speech-recognition-status">Click the mic button to start speaking...</span>
            </div>
            <div class="transcript-container">
                <!-- Transcription output -->
                @Html.EJS().ChatUI("transcript-content").ShowHeader(false).ShowFooter(false).AutoScrollToBottom(true).Created("onCreate").EmptyChatTemplate("#emptyChatTemplate").TypingUsersTemplate("#typingIndicatorTemplate").TimeStampFormat("MMM d, h:mm a").Render()
            </div>
        </div>
    </div>
}

<script>

    var user = { id: 'testing-user', user: 'Testing User' };
    var msgIdx = -1;
    var isIndicatorVisible = false;
    var chatUIObj;
    var speechToTextObj;

    function onCreate() {
        chatUIObj = ej.base.getComponent(document.getElementById("transcript-content"), "chat-ui");
        speechToTextObj = new ej.inputs.SpeechToText({
            buttonSettings: {
                stopIconCss: 'e-icons e-listen-icon'
            },
            transcriptChanged: onTranscriptChange,
            onStart: onListeningStart,
            onStop: onListeningStop,
            onError: onErrorHandler,
            cssClass: 'usecase-stt-btn'
        });
        speechToTextObj.appendTo('#speechToText');
    }

    function onTranscriptChange(args) {
        var existingMsg = chatUIObj.messages[msgIdx];
        if (existingMsg) {
            chatUIObj.updateMessage({ text: args.transcript }, existingMsg.id);
            chatUIObj.scrollToBottom();
        } else {
            var newMsg = { id: 'msg-' + (msgIdx + 1), text: args.transcript, author: user };
            chatUIObj.addMessage(newMsg);
        }

        // Show typing indicator only if it's not visible
        if (!isIndicatorVisible) {
            chatUIObj.typingUsers = [user];
            isIndicatorVisible = true;
        }

        // Final transcript
        if (!args.isInterimResult) {
            msgIdx++;
            speechToTextObj.transcript = '';
            chatUIObj.typingUsers = [];
            isIndicatorVisible = false;
        }
    }

    // Event handler for listening start
    function onListeningStart() {
        msgIdx = chatUIObj.messages.length;
        this.element.classList.add('stt-listening-state');
        updateStatus('Listening... Speak now...');
    }

    // Event handler for listening stop
    function onListeningStop(args) {
        this.element.classList.remove('stt-listening-state');
        chatUIObj.typingUsers = [];
        if (args.isInteracted)
            updateStatus('Click the mic button to start speaking...');
    }

    // Event handler for errors
    function onErrorHandler(args) {
        updateStatus(args.errorMessage);
        if (args.error === 'unsupported-browser') {
            speechToTextObj.disabled = true;
        }
    }

    // Function to updates the speech recognition status message
    function updateStatus(status) {
        document.querySelector('.speech-recognition-status').innerText = status;
    }

</script>

<script id="emptyChatTemplate" type="text/x-jsrender">
    <div class="empty-chat">
        <span class="e-icons e-multiple-comment"></span>
        No transcript available. Start speaking to generate a transcript.
    </div>
</script>

<script id="typingIndicatorTemplate" type="text/x-jsrender">
    <div class="e-typing-indicator ">
        <span class="e-user-text">Transcripting</span>
        <div class="e-indicator-wrapper">
            <span class="e-indicator"></span>
            <span class="e-indicator">
            </span><span class="e-indicator">
            </span>
        </div>
    </div>
</script>

<style>
    .usecase-speechToText-section,
    .e-bigger .usecase-speechToText-section {
        width: 90%;
        height: 55vh;
        margin: 0 auto;
        padding: 0;
        display: flex;
    }

    .usecase-speechToText-section #transcript-content {
        border: none;
        border-top-right-radius: 8px;
        border-bottom-right-radius: 8px;
    }

    .usecase-speechToText-section .stt-container {
        width: 70%;
        height: 100%;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        gap: 40px;
    }

    .usecase-speechToText-section .e-speech-to-text.usecase-stt-btn {
        width: 100px;
        height: 100px;
        position: relative;
    }

    .usecase-speechToText-section .usecase-stt-btn .e-btn-icon,
    .e-bigger .usecase-speechToText-section .usecase-stt-btn .e-btn-icon {
        font-size: 50px;
    }

    .usecase-speechToText-section .transcript-container {
        width: 30%;
        height: 100%;
    }

    /* Create wave effect using pseudo-elements */
    .usecase-stt-btn::before,
    .usecase-stt-btn::after {
        content: "";
        position: absolute;
        top: 50%;
        left: 50%;
        width: 100%;
        height: 100%;
        border-radius: 50%;
        background: #9b9b9b;
        transform: translate(-50%, -50%) scale(1);
        opacity: 0;
        pointer-events: none;
    }

    .usecase-speechToText-section .stt-listening-state::before {
        animation: stt-wave-ring 1.5s infinite ease-out;
    }

    .usecase-speechToText-section .stt-listening-state::after {
        animation: stt-wave-ring 1.5s 0.75s infinite ease-out; /* Slight delay for second wave */
    }

    @@keyframes stt-wave-ring {
        0% {
            transform: translate(-50%, -50%) scale(1);
            opacity: 0.8;
        }
        100% {
            transform: translate(-50%, -50%) scale(2);
            opacity: 0;
        }
    }

    .usecase-speechToText-section .empty-chat {
        width: 90%;
        display: flex;
        justify-content: center;
        align-items: center;
        font-size: 15px;
        flex-direction: column;
        gap: 10px;
        text-align: center;
        margin: auto;
    }

    .usecase-speechToText-section .empty-chat .e-multiple-comment {
        font-size: 50px;
    }

    .usecase-speechToText-section #transcript-content.e-chat-ui .e-message-group {
        max-width: 95%;
    }

    @@media only screen and (max-width: 850px) {
        .usecase-speechToText-section,
        .e-bigger .usecase-speechToText-section {
            flex-direction: column;
            height: 70vh;
        }
        .usecase-speechToText-section .transcript-container {
            width: 100%;
            height: 70vh;
            overflow: scroll;
        }
        .usecase-speechToText-section .stt-container {
            width: 100%;
            height: 55%;
        }
    }
</style>

@section Meta{
    <meta name="description" content="This example demonstrates the Use case in ASP.NET MVC Speech To Text control. Explore here for more details." />
}
@section ActionDescription{
    <div id="action-description">
        <p>This sample demonstrates a live transcription feature that converts spoken words into text in real-time. Click the microphone button to start speaking, and the transcribed text will appear in the ChatUI control as a conversation with timestamps.</p>
    </div>
}
@section Description{
    <div id="description">
        <p>
            The Speech-to-Text control captures audio input and transcribes it dynamically, updating the transcript in the <code>ChatUI</code> control. Each spoken segment is displayed as an individual message with a timestamp, ensuring a structured conversation format.
        </p>
        <p>
            The integration with <code>ChatUI</code> allows real-time updates, maintaining the natural flow of conversation. This setup enhances readability and interaction, making it easier to follow and review the transcription.
        </p>
    </div>
}
@section Title{
    <title>ASP.NET MVC Speech To Text Use case Example - Syncfusion Demos </title>
}
@section Header{
    <h1 class='sb-sample-text'>Example of Use case in ASP.NET MVC Speech To Text Control</h1>
}